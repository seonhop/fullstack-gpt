{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "# Need to have OPENAI_API_KEY variable in the .env file\n",
    "# Or pass `open_ai_key` as a named parameter\n",
    "\n",
    "chat = ChatOpenAI(model = \"gpt-4o-mini\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi! How can I assist you today?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiation using from_template (recommended)\n",
    "template = PromptTemplate.from_template(\"Say {foo}\")\n",
    "prompt = template.format(foo = \"Hi\")\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Got unknown type ('input_variables', [])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m\n\u001b[1;32m      8\u001b[0m examples_prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(examples)\n\u001b[1;32m     10\u001b[0m prompt \u001b[39m=\u001b[39m ChatPromptTemplate\u001b[39m.\u001b[39mfrom_messages([\n\u001b[1;32m     11\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mYou are a medical expert. Your task is to differentiate between serious pathology and treatable pathology based on patient intake form\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     12\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mai\u001b[39m\u001b[39m\"\u001b[39m, examples_prompt),\n\u001b[1;32m     13\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mNow, classify the following intake form: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Patient Name: John Doe | Age: 55 | Gender: Male | Primary Complaint: Lower back pain | Duration of Symptoms: 3 weeks | Pain Severity (0-10): 7 | Pain Description: Sharp pain radiating down the right leg | Previous Injuries/Surgeries: None | Medical History: Hypertension, Type 2 Diabetes | Current Medications: Metformin, Lisinopril | Red Flag Symptoms: Unexplained weight loss, Numbness in legs | Daily Activities Affected: Difficulty sitting for long periods, Trouble lifting objects | Goals for Physical Therapy: Pain relief, Improved mobility\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m ])\n\u001b[0;32m---> 16\u001b[0m chat\u001b[39m.\u001b[39;49mpredict_messages(prompt)\n",
      "File \u001b[0;32m~/Documents/GitHub/PT/fullstack-gpt/.venv/lib/python3.11/site-packages/langchain/chat_models/base.py:653\u001b[0m, in \u001b[0;36mBaseChatModel.predict_messages\u001b[0;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    652\u001b[0m     _stop \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(stop)\n\u001b[0;32m--> 653\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(messages, stop\u001b[39m=\u001b[39;49m_stop, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/PT/fullstack-gpt/.venv/lib/python3.11/site-packages/langchain/chat_models/base.py:600\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    594\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    595\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    599\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[0;32m--> 600\u001b[0m     generation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m    601\u001b[0m         [messages], stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    602\u001b[0m     )\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    603\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[1;32m    604\u001b[0m         \u001b[39mreturn\u001b[39;00m generation\u001b[39m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/Documents/GitHub/PT/fullstack-gpt/.venv/lib/python3.11/site-packages/langchain/chat_models/base.py:349\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n\u001b[1;32m    348\u001b[0m             run_managers[i]\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 349\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    350\u001b[0m flattened_outputs \u001b[39m=\u001b[39m [\n\u001b[1;32m    351\u001b[0m     LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations], llm_output\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mllm_output)\n\u001b[1;32m    352\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\n\u001b[1;32m    353\u001b[0m ]\n\u001b[1;32m    354\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/Documents/GitHub/PT/fullstack-gpt/.venv/lib/python3.11/site-packages/langchain/chat_models/base.py:339\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(messages):\n\u001b[1;32m    337\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m         results\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 339\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_with_cache(\n\u001b[1;32m    340\u001b[0m                 m,\n\u001b[1;32m    341\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    342\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[i] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    343\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    344\u001b[0m             )\n\u001b[1;32m    345\u001b[0m         )\n\u001b[1;32m    346\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    347\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Documents/GitHub/PT/fullstack-gpt/.venv/lib/python3.11/site-packages/langchain/chat_models/base.py:492\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    489\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m     )\n\u001b[1;32m    491\u001b[0m \u001b[39mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 492\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    493\u001b[0m         messages, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    494\u001b[0m     )\n\u001b[1;32m    495\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(messages, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/PT/fullstack-gpt/.venv/lib/python3.11/site-packages/langchain/chat_models/openai.py:410\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m     stream_iter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream(\n\u001b[1;32m    407\u001b[0m         messages, stop\u001b[39m=\u001b[39mstop, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    408\u001b[0m     )\n\u001b[1;32m    409\u001b[0m     \u001b[39mreturn\u001b[39;00m _generate_from_stream(stream_iter)\n\u001b[0;32m--> 410\u001b[0m message_dicts, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_message_dicts(messages, stop)\n\u001b[1;32m    411\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[1;32m    412\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompletion_with_retry(\n\u001b[1;32m    413\u001b[0m     messages\u001b[39m=\u001b[39mmessage_dicts, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    414\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/PT/fullstack-gpt/.venv/lib/python3.11/site-packages/langchain/chat_models/openai.py:425\u001b[0m, in \u001b[0;36mChatOpenAI._create_message_dicts\u001b[0;34m(self, messages, stop)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`stop` found in both the input and default params.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    424\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m stop\n\u001b[0;32m--> 425\u001b[0m message_dicts \u001b[39m=\u001b[39m [convert_message_to_dict(m) \u001b[39mfor\u001b[39;49;00m m \u001b[39min\u001b[39;49;00m messages]\n\u001b[1;32m    426\u001b[0m \u001b[39mreturn\u001b[39;00m message_dicts, params\n",
      "File \u001b[0;32m~/Documents/GitHub/PT/fullstack-gpt/.venv/lib/python3.11/site-packages/langchain/chat_models/openai.py:425\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`stop` found in both the input and default params.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    424\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m stop\n\u001b[0;32m--> 425\u001b[0m message_dicts \u001b[39m=\u001b[39m [convert_message_to_dict(m) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages]\n\u001b[1;32m    426\u001b[0m \u001b[39mreturn\u001b[39;00m message_dicts, params\n",
      "File \u001b[0;32m~/Documents/GitHub/PT/fullstack-gpt/.venv/lib/python3.11/site-packages/langchain/adapters/openai.py:100\u001b[0m, in \u001b[0;36mconvert_message_to_dict\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m     94\u001b[0m     message_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m     95\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mfunction\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: message\u001b[39m.\u001b[39mcontent,\n\u001b[1;32m     97\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: message\u001b[39m.\u001b[39mname,\n\u001b[1;32m     98\u001b[0m     }\n\u001b[1;32m     99\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot unknown type \u001b[39m\u001b[39m{\u001b[39;00mmessage\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m message\u001b[39m.\u001b[39madditional_kwargs:\n\u001b[1;32m    102\u001b[0m     message_dict[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m message\u001b[39m.\u001b[39madditional_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: Got unknown type ('input_variables', [])"
     ]
    }
   ],
   "source": [
    "ex1 = \"Patient Name: Sarah Johnson | Age: 40 | Gender: Female | Primary Complaint: Neck pain | Duration of Symptoms: 1 week | Pain Severity (0-10): 4 | Pain Description: Dull ache, localized to the base of the skull | Previous Injuries/Surgeries: None | Medical History: Anxiety | Current Medications: None | Red Flag Symptoms: None | Daily Activities Affected: Difficulty turning head when driving | Goals for Physical Therapy: Pain relief and improved range of motion | Classification: Treatable pathology (Physical therapy)\"\n",
    "ex2 = \"Patient Name: Mark Lee | Age: 60 | Gender: Male | Primary Complaint: Severe shoulder pain | Duration of Symptoms: 4 months | Pain Severity (0-10): 9 | Pain Description: Sharp, stabbing pain, especially at night | Previous Injuries/Surgeries: Rotator cuff surgery 2 years ago | Medical History: Hypertension | Current Medications: Lisinopril | Red Flag Symptoms: None | Daily Activities Affected: Inability to lift the arm overhead, Trouble sleeping due to pain | Goals for Physical Therapy: Pain relief, Restored function | Classification: Treatable pathology (Physical therapy)\"\n",
    "ex3 = \"Patient Name: Emily Davis | Age: 70 | Gender: Female | Primary Complaint: Unexplained weight loss and upper back pain | Duration of Symptoms: 2 months | Pain Severity (0-10): 6 | Pain Description: Constant, dull pain in the upper back | Previous Injuries/Surgeries: None | Medical History: Osteoporosis | Current Medications: Calcium supplements, Vitamin D | Red Flag Symptoms: Unexplained weight loss | Daily Activities Affected: Trouble standing for long periods | Goals for Physical Therapy: Pain management, Improved posture | Classification: Serious pathology (Referral recommended)\"\n",
    "ex4 = \"Patient Name: James Wilson | Age: 50 | Gender: Male | Primary Complaint: Knee pain after jogging | Duration of Symptoms: 2 weeks | Pain Severity (0-10): 5 | Pain Description: Aching pain, worse after activity | Previous Injuries/Surgeries: None | Medical History: None | Current Medications: None | Red Flag Symptoms: None | Daily Activities Affected: Difficulty with stairs, Discomfort during exercise | Goals for Physical Therapy: Pain relief, Return to running | Classification: Treatable pathology (Physical therapy)\"\n",
    "ex5 = \"Patient Name: Linda Green | Age: 65 | Gender: Female | Primary Complaint: Severe back pain with leg numbness | Duration of Symptoms: 3 months | Pain Severity (0-10): 8 | Pain Description: Severe, shooting pain down the left leg | Previous Injuries/Surgeries: None | Medical History: Type 2 Diabetes | Current Medications: Metformin | Red Flag Symptoms: Numbness in legs, Difficulty controlling bladder | Daily Activities Affected: Inability to walk long distances, Trouble sleeping due to pain | Goals for Physical Therapy: Pain relief, Restored function | Classification: Serious pathology (Referral recommended)\"\n",
    "input = \"Patient Name: John Doe | Age: 55 | Gender: Male | Primary Complaint: Lower back pain | Duration of Symptoms: 3 weeks | Pain Severity (0-10): 7 | Pain Description: Sharp pain radiating down the right leg | Previous Injuries/Surgeries: None | Medical History: Hypertension, Type 2 Diabetes | Current Medications: Metformin, Lisinopril | Red Flag Symptoms: Unexplained weight loss, Numbness in legs | Daily Activities Affected: Difficulty sitting for long periods, Trouble lifting objects | Goals for Physical Therapy: Pain relief, Improved mobility\"\n",
    "examples = [ex1, ex2, ex3, ex4, ex5]\n",
    "examples_prompt = \"\\n\".join(examples)\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a medical expert. Your task is to differentiate between serious pathology and treatable pathology based on patient intake form\"),\n",
    "    (\"ai\", examples_prompt),\n",
    "    (\"human\", \"Now, classify the following intake form: \\n {intake_form_data}\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(intake_form_data = input)\n",
    "\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
